<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>TensorFlow.js Image Classification</title>
	<script src="js/p5.min.js"></script>
	<script src="js/ml5.min.js"></script>
	<style>
		body{
			margin: 0;
		}
	</style>
</head>

<body>
	<script>
		/*
		 * üëã Hello! This is an ml5.js example made and shared with ‚ù§Ô∏è.
		 * Learn more about the ml5.js project: https://ml5js.org/
		 * ml5.js license and Code of Conduct: https://github.com/ml5js/ml5-next-gen/blob/main/LICENSE.md
		 *
		 * This example demonstrates drawing skeletons on poses for the MoveNet model.
		 */

		// Ëé∑ÂèñÊµèËßàÂô®Á™óÂè£ÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶
		var screenWidth = window.innerWidth || document.documentElement.clientWidth || document.body.clientWidth;
		var screenHeight = window.innerHeight || document.documentElement.clientHeight || document.body.clientHeight;

		console.log('1111111111111',screenWidth,screenHeight)

		let video;
		let bodyPose;
		let poses = [];
		let connections;

		function preload() {
			// Load the bodyPose model
			bodyPose = ml5.bodyPose();
		}

		function setup() {
			createCanvas(screenWidth, screenHeight);

			// Create the video and hide it
			video = createCapture(VIDEO);
			video.size(screenWidth, screenHeight);
			video.hide();

			// Start detecting poses in the webcam video
			bodyPose.detectStart(video, gotPoses);
			// Get the skeleton connection information
			connections = bodyPose.getSkeleton();
		}

		function draw() {
			// Draw the webcam video
			image(video, 0, 0, width, height);

			// Draw the skeleton connections
			for (let i = 0; i < poses.length; i++) {
				let pose = poses[i];
				for (let j = 0; j < connections.length; j++) {
					let pointAIndex = connections[j][0];
					let pointBIndex = connections[j][1];
					let pointA = pose.keypoints[pointAIndex];
					let pointB = pose.keypoints[pointBIndex];
					// Only draw a line if both points are confident enough
					if (pointA.confidence > 0.1 && pointB.confidence > 0.1) {
						stroke(255, 0, 0);
						strokeWeight(2);
						line(pointA.x, pointA.y, pointB.x, pointB.y);
					}
				}
			}

			// Draw all the tracked landmark points
			for (let i = 0; i < poses.length; i++) {
				let pose = poses[i];
				for (let j = 0; j < pose.keypoints.length; j++) {
					let keypoint = pose.keypoints[j];
					// Only draw a circle if the keypoint's confidence is bigger than 0.1
					if (keypoint.confidence > 0.1) {
						fill(0, 255, 0);
						noStroke();
						circle(keypoint.x, keypoint.y, 10);
					}
				}
			}
		}

		// Callback function for when bodyPose outputs data
		function gotPoses(results) {
			// Save the output to the poses variable
			poses = results;
		}
	</script>
</body>

</html>